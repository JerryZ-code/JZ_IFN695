{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pre-process the files\n",
    "def process_file(file_path):    \n",
    "    # df = pd.read_csv(\"aemo_data/High_Impact_Outages_20210830.csv\", encoding='latin1')\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "    # certain columns have \\n and \\r, so they are removed\n",
    "    df = df.replace({r\"\\r|\\n\": \" \"}, regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[\\r\\n]\", \" \", regex=True)\n",
    "\n",
    "    # drop the columns which are Unnamed and have no values (total of 7 columns)\n",
    "    df = df.iloc[:, :-7]\n",
    "\n",
    "    # pre-processing on the columns\n",
    "    # extract information from the 'start' and 'finish' columns and separate into separate columns\n",
    "    pattern = r\"(\\d{2}/\\d{2}/\\d{4})\\s+(\\d{2}:\\d{2})\\s+(\\w+)\"\n",
    "    df[[\"Start_Date\", \"Start_Time\", \"Start_Day\"]] = df[\"Start\"].str.extract(pattern)\n",
    "    df[[\"Finish_Date\", \"Finish_Time\", \"Finish_Day\"]] = df[\"Finish\"].str.extract(pattern)\n",
    "    df['Start_Date'] = pd.to_datetime(df['Start_Date'], dayfirst=True)\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time']).dt.strftime('%H:%M:%S')\n",
    "    df['Finish_Date'] = pd.to_datetime(df['Finish_Date'], dayfirst=True)\n",
    "    df['Finish_Time'] = pd.to_datetime(df['Finish_Time']).dt.strftime('%H:%M:%S')\n",
    "\n",
    "    # extract information from 'recall'\n",
    "    pattern = r\"Day:\\s*(\\d+)\\s*hr?s?(?:-Night:\\s*(\\d+)\\s*hr?s?)?\"\n",
    "    df[[\"Recall_Day_Hours\", \"Recall_Night_Hours\"]] = df[\"Recall\"].str.extract(pattern)\n",
    "    df[\"Recall_Day_Hours\"] = pd.to_numeric(df[\"Recall_Day_Hours\"], errors=\"coerce\")\n",
    "    df[\"Recall_Night_Hours\"] = pd.to_numeric(df[\"Recall_Night_Hours\"], errors=\"coerce\")\n",
    "\n",
    "    # extract information from 'reason'\n",
    "    df[\"Reason\"] = df[\"Reason and  Duration\"].str.extract(r\"([a-zA-Z\\s]+)\")\n",
    "\n",
    "    # extract information from 'duration'\n",
    "    pattern = r\"([\\d\\.]+)\\s*(Days?|Hours?|Minutes?)\"\n",
    "    df[[\"Value\", \"Unit\"]] = df[\"Duration\"].str.extract(pattern)\n",
    "    df[\"Value\"] = df[\"Value\"].astype(float)\n",
    "    df[\"Duration_Hours\"] = df.apply(\n",
    "        lambda row: row[\"Value\"] * 24 if pd.notnull(row[\"Unit\"]) and \"Day\" in row[\"Unit\"]  # Convert Days to Hours\n",
    "        else row[\"Value\"] if pd.notnull(row[\"Unit\"]) and \"Hour\" in row[\"Unit\"]  # Keep Hours as is\n",
    "        else row[\"Value\"] / 60 if pd.notnull(row[\"Unit\"]) and \"Minute\" in row[\"Unit\"]  # Convert Minutes to Hours\n",
    "        else None, axis=1  # Handle any unexpected cases\n",
    "    )\n",
    "\n",
    "    # split information from 'status'\n",
    "    df[[\"Status_Description\", \"Status_Code\"]] = df[\"Status\"].str.split(\" - \", expand=True)\n",
    "    # Split information from 'status and market notice'\n",
    "    df[['Status_Description_Market', 'Market_Notice_Code']] = df['Status and  Market Notice'].str.split(\" - \", expand=True)\n",
    "\n",
    "    # List of boolean columns\n",
    "    bool_cols = ['Project Work?', 'Unplanned?', 'Generator Aware?', 'DNSP Aware?', 'Inter-Regional']\n",
    "    # Replace 'T' with 1 and NaN with 0\n",
    "    df[bool_cols] = df[bool_cols].applymap(lambda x: 1 if x == 'T' else 0)\n",
    "\n",
    "    # drop non-needed columns now:\n",
    "    df.drop(columns=['Start', 'Finish', 'Status', 'Status and  Market Notice', 'Duration', 'Value', 'Unit',\n",
    "                    'Reason and  Duration', 'Recall', 'Start', 'Finish'], inplace=True)\n",
    "\n",
    "    # re-order columns\n",
    "    cols = list(df.columns)\n",
    "    new_col_order = ['Region', 'NSP', \n",
    "                    'Start_Date', 'Start_Time', 'Start_Day', # Start time information\n",
    "                    'Finish_Date', 'Finish_Time', 'Finish_Day', # End time information\n",
    "                    'Network Asset', # identifying information\n",
    "                    'Recall_Day_Hours', 'Recall_Night_Hours', # recall information\n",
    "                    'Project Work?', 'Unplanned?', 'DNSP Aware?', 'Generator Aware?', 'Inter-Regional', # boolean terms\n",
    "                    'Status_Description', 'Status_Code', 'Status_Description_Market', 'Market_Notice_Code', # status information\n",
    "                    'Reason', 'Duration_Hours', # reason and duration information\n",
    "                    'Impact'\n",
    "                    ]\n",
    "    new_col_order = list(dict.fromkeys(new_col_order))\n",
    "    df = df[new_col_order]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry Z\\AppData\\Local\\Temp\\ipykernel_92280\\366290200.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Start_Time'] = pd.to_datetime(df['Start_Time']).dt.strftime('%H:%M:%S')\n",
      "C:\\Users\\Jerry Z\\AppData\\Local\\Temp\\ipykernel_92280\\366290200.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Finish_Time'] = pd.to_datetime(df['Finish_Time']).dt.strftime('%H:%M:%S')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Reason and  Duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jerry Z\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Reason and  Duration'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Loop through each file, apply the processing function and collect the results\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m csv_files:\n\u001b[1;32m----> 9\u001b[0m     processed_df \u001b[38;5;241m=\u001b[39m process_file(file)\n\u001b[0;32m     10\u001b[0m     processed_dfs\u001b[38;5;241m.\u001b[39mappend(processed_df)\n",
      "Cell \u001b[1;32mIn[42], line 30\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     27\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall_Night_Hours\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall_Night_Hours\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# extract information from 'reason'\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReason\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReason and  Duration\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([a-zA-Z\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]+)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# extract information from 'duration'\u001b[39;00m\n\u001b[0;32m     33\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(Days?|Hours?|Minutes?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jerry Z\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Jerry Z\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Reason and  Duration'"
     ]
    }
   ],
   "source": [
    "# List of CSV files to process\n",
    "csv_files = glob.glob(\"aemo_data/*.csv\")\n",
    "\n",
    "# List to store processed dataframes\n",
    "processed_dfs = []\n",
    "\n",
    "# Loop through each file, apply the processing function and collect the results\n",
    "for file in csv_files:\n",
    "    processed_df = process_file(file)\n",
    "    processed_dfs.append(processed_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
